#!/usr/bin/env python3
"""
Telegram Command Poller â€” GPT Router edition.
Receives natural language â†’ GPT Router â†’ local/claude/none â†’ response.
"""
import os
import sys
import json
import time
import urllib.parse
import urllib.request

sys.path.insert(0, "/root/trading-bot/app")
import gpt_router
import local_query_executor
import emergency_detector

ENV_PATH = "/root/trading-bot/app/telegram_cmd.env"
ENV_FALLBACKS = [
    "/root/trading-bot/app/.backup_20260211/telegram_cmd.env",
    "/root/trading-bot/app/_recovered/telegram_cmd.env",
]
LOG_PREFIX = "[tg_poller]"
ERR_LOG = "/root/trading-bot/app/telegram_cmd_poller.err"

# â”€â”€ telegram plumbing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _log_err(msg: str):
    try:
        with open(ERR_LOG, "a", encoding="utf-8") as f:
            f.write(f"{time.strftime('%Y-%m-%d %H:%M:%S')} {msg}\n")
    except Exception:
        pass

def load_env(path: str) -> dict:
    candidates = [path] + ENV_FALLBACKS
    for p in candidates:
        if os.path.isfile(p):
            env = {}
            with open(p, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#") or "=" not in line:
                        continue
                    k, v = line.split("=", 1)
                    env[k.strip()] = v.strip()
            if p != path:
                _log(f"WARNING: primary env missing ({path}), loaded fallback: {p}")
                _log_err(f"WARNING: loaded fallback env from {p}")
            return env
    raise FileNotFoundError(
        f"telegram_cmd.env not found in any of: {candidates}"
    )

def read_offset(path: str) -> int:
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return int(data.get("lastUpdateId", 0))
    except Exception:
        return 0

def write_offset(path: str, last_update_id: int) -> None:
    data = {"version": 1, "lastUpdateId": int(last_update_id)}
    tmp = path + ".tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    os.replace(tmp, path)

def tg_api_call(token: str, method: str, params: dict) -> dict:
    url = f"https://api.telegram.org/bot{token}/{method}"
    data = urllib.parse.urlencode(params).encode("utf-8")
    req = urllib.request.Request(url, data=data, method="POST")
    with urllib.request.urlopen(req, timeout=20) as resp:
        body = resp.read().decode("utf-8")
    return json.loads(body)

def send_message(token: str, chat_id: int, text: str) -> None:
    chunks = []
    s = text or ""
    while len(s) > 3800:
        chunks.append(s[:3800])
        s = s[3800:]
    chunks.append(s)
    for c in chunks:
        tg_api_call(token, "sendMessage", {
            "chat_id": str(chat_id), "text": c,
            "disable_web_page_preview": "true",
        })

def _log(msg):
    print(f"{LOG_PREFIX} {msg}", flush=True)

# â”€â”€ help text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

HELP_TEXT = (
    "ğŸ¦… OpenClaw ì½˜ì†” (GPT Router)\n"
    "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    "ğŸ“Œ ëª…ë ¹ì–´\n"
    "  /help   ë„ì›€ë§\n"
    "  /status ë´‡ ìƒíƒœ\n"
    "  /health ì„œë¹„ìŠ¤ ìƒíƒœ\n"
    "\n"
    "ğŸ’¬ ìì—°ì–´ ì˜ˆì‹œ\n"
    "  ìƒíƒœ ë³´ì—¬ì¤˜\n"
    "  BTC ì§€ê¸ˆ ì–¼ë§ˆì•¼?\n"
    "  RSIë‘ í¬ì§€ì…˜ ë³´ì—¬ì¤˜\n"
    "  ìµœê·¼ 30ë¶„ ë‰´ìŠ¤\n"
    "  ì˜¤ëŠ˜ ë§¤ë§¤ì „ëµ ì¡ì•„ì¤˜\n"
    "  ê¸‰ë³€ í›„ ë°©í–¥ì„± ë¶„ì„í•´ì¤˜\n"
    "  ì†ì ˆ ì›ì¸ ë¶„ì„í•´ì¤˜\n"
    "  ìµœê·¼ ì—ëŸ¬ ë­ì•¼?\n"
    "  ë¦¬í¬íŠ¸ ë³´ì—¬ì¤˜\n"
)

# â”€â”€ news importance check & AI news advisory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _check_news_importance():
    """DBì—ì„œ ìµœê·¼ 1ì‹œê°„ ê³ ì˜í–¥ ë‰´ìŠ¤ í™•ì¸. impact_score >= 7 ë‰´ìŠ¤ ë°˜í™˜."""
    try:
        import psycopg2
        db_cfg = dict(
            host=os.getenv("DB_HOST", "localhost"),
            port=int(os.getenv("DB_PORT", "5432")),
            dbname=os.getenv("DB_NAME", "trading"),
            user=os.getenv("DB_USER", "bot"),
            password=os.getenv("DB_PASS", "botpass"),
            connect_timeout=10,
            options="-c statement_timeout=30000",
        )
        conn = psycopg2.connect(**db_cfg)
        conn.autocommit = True
        with conn.cursor() as cur:
            cur.execute("""
                SELECT id, title, impact_score, summary
                FROM public.news
                WHERE ts >= now() - interval '1 hour'
                  AND impact_score >= 7
                ORDER BY impact_score DESC, id DESC
                LIMIT 5
            """)
            rows = cur.fetchall()
        conn.close()
        if rows:
            return [
                {"id": r[0], "title": r[1], "impact_score": r[2], "summary": r[3]}
                for r in rows
            ]
        return None
    except Exception as e:
        _log(f"_check_news_importance error: {e}")
        return None


def _ai_news_advisory(text: str, high_news: list) -> str:
    """ê³ ì˜í–¥ ë‰´ìŠ¤ì— ëŒ€í•œ AI ë¶„ì„. Advisory only."""
    news_lines = []
    for n in high_news[:3]:
        news_lines.append(
            f"- [{n['impact_score']}/10] {n['title']}\n  {n.get('summary', '')}"
        )
    news_block = "\n".join(news_lines)

    ind = local_query_executor.execute("indicator_snapshot")

    prompt = (
        f"ì‚¬ìš©ì ìš”ì²­: {text}\n\n"
        f"ê³ ì˜í–¥ ë‰´ìŠ¤ (ìµœê·¼ 1ì‹œê°„):\n{news_block}\n\n"
        f"í˜„ì¬ ì§€í‘œ:\n{ind}\n\n"
        "ë¶„ì„ ìš”ì²­:\n"
        "1. ê° ë‰´ìŠ¤ì˜ BTC ì„ ë¬¼ ì˜í–¥ ë°©í–¥/í¬ê¸°\n"
        "2. ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ (ìƒìŠ¹/í•˜ë½/íš¡ë³´)\n"
        "3. ëŒ€ì‘ í¬ì¸íŠ¸\n"
        "â€» ë§¤ë§¤ ì‹¤í–‰ ê¶Œí•œ ì—†ìŒ. ë¶„ì„/ê¶Œê³ ë§Œ. 600ì ì´ë‚´."
    )
    result, meta = _call_claude_advisory(prompt)
    _save_advisory('news_advisory',
                   {'user_text': text, 'high_news': high_news, 'indicators': ind},
                   result, meta)
    return result


# â”€â”€ AI advisory (route=claude) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _ai_advisory(intent: dict, text: str) -> str:
    """Generate AI advisory. Advisory only â€” never executes trades."""
    intent_type = intent.get("intent", "other")
    claude_prompt = intent.get("claude_prompt", "") or text

    # budget gate
    state = gpt_router._load_state()
    allowed, is_gear2 = gpt_router._check_budget(state)
    if not allowed:
        return "âš ï¸ AI ì˜ˆì‚° í•œë„ ë„ë‹¬. ë¡œì»¬ ì¡°íšŒëŠ” ê°€ëŠ¥í•©ë‹ˆë‹¤: /status, /health, ë‰´ìŠ¤ ìš”ì•½"

    if intent_type == "emergency":
        return _ai_emergency_advisory(claude_prompt)
    elif intent_type == "strategy":
        return _ai_strategy_advisory(claude_prompt)
    elif intent_type == "news":
        return _ai_news_claude_advisory(claude_prompt)
    else:
        return _ai_general_advisory(claude_prompt)


def _ai_news_claude_advisory(text: str) -> str:
    """News analysis via Claude. Fetches recent news + indicators."""
    parts = []

    # Recent news (broader window)
    news = local_query_executor.execute("news_summary", "ìµœê·¼ 6ì‹œê°„ ë‰´ìŠ¤ 10ê°œ")
    parts.append(f"ìµœê·¼ ë‰´ìŠ¤:\n{news[:800]}")

    # High impact news if any
    high = _check_news_importance()
    if high:
        high_lines = []
        for n in high[:3]:
            high_lines.append(
                f"- [{n['impact_score']}/10] {n['title']}\n  {n.get('summary', '')}")
        parts.append(f"ê³ ì˜í–¥ ë‰´ìŠ¤:\n" + "\n".join(high_lines))

    # Indicators + price
    ind = local_query_executor.execute("indicator_snapshot")
    parts.append(f"ì§€í‘œ:\n{ind}")

    # Score
    score = local_query_executor.execute("score_summary")
    parts.append(f"ìŠ¤ì½”ì–´:\n{score}")

    # Position
    pos = local_query_executor.execute("position_info")
    parts.append(f"í¬ì§€ì…˜:\n{pos}")

    prompt = (
        f"ë‹¹ì‹ ì€ ë¹„íŠ¸ì½”ì¸ ì„ ë¬¼ íŠ¸ë ˆì´ë”© ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
        f"ì•„ë˜ ì œê³µëœ ì‹¤ì‹œê°„ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”.\n\n"
        f"ì‚¬ìš©ì ìš”ì²­: {text}\n\n"
        f"=== ì‹¤ì‹œê°„ ë°ì´í„° ===\n" + "\n\n".join(parts) + "\n\n"
        "=== ë¶„ì„ ìš”ì²­ ===\n"
        "1. ê° ë‰´ìŠ¤ì˜ BTC ì„ ë¬¼ ì˜í–¥ ë°©í–¥/í¬ê¸° í‰ê°€\n"
        "2. ì¢…í•© ì‹œë‚˜ë¦¬ì˜¤ (ìƒìŠ¹/í•˜ë½/íš¡ë³´)\n"
        "3. í˜„ì¬ í¬ì§€ì…˜ ê¸°ì¤€ ëŒ€ì‘ í¬ì¸íŠ¸\n"
        "â€» ë§¤ë§¤ ì‹¤í–‰ ê¶Œí•œ ì—†ìŒ. ë¶„ì„/ê¶Œê³ ë§Œ. 800ì ì´ë‚´."
    )
    result, meta = _call_claude_advisory(prompt)
    _save_advisory('news_advisory',
                   {'user_text': text, 'news': news[:800], 'indicators': ind,
                    'score': score, 'position': pos},
                   result, meta)
    return result


def _ai_emergency_advisory(text: str) -> str:
    """Emergency: gather detector data + AI analysis."""
    # run emergency checks
    alert_data = emergency_detector.run_check()
    alert_summary = emergency_detector.format_alerts(alert_data) if alert_data else "í˜„ì¬ ê¸´ê¸‰ ê°ì§€ ì—†ìŒ"

    context_str = ""
    if alert_data and alert_data.get("context"):
        context_str = json.dumps(alert_data["context"], ensure_ascii=False, default=str)

    prompt = (
        f"ì‚¬ìš©ì ìš”ì²­: {text}\n\n"
        f"ê¸´ê¸‰ ê°ì§€ ê²°ê³¼:\n{alert_summary}\n\n"
        f"ì‹œì¥ ì»¨í…ìŠ¤íŠ¸:\n{context_str}\n\n"
        "ë¶„ì„ ìš”ì²­:\n"
        "1. ê¸‰ë³€ ì›ì¸ ë¶„ë¥˜ (ë§¤í¬ë¡œ/ê¸°ìˆ ì /ë‰´ìŠ¤)\n"
        "2. ì‹œë‚˜ë¦¬ì˜¤ 3ê°œ: íšŒë³µ / ì¶”ì„¸ì „í™˜ / ì¶”ì„¸ì§€ì†\n"
        "3. 10~30ë¶„ ì²´í¬í¬ì¸íŠ¸ 3ê°œ\n"
        "4. ë¦¬ìŠ¤í¬ ëª¨ë“œ ê¶Œê³ \n"
        "â€» ë§¤ë§¤ ì‹¤í–‰ ê¶Œí•œ ì—†ìŒ. ë¶„ì„/ê¶Œê³ ë§Œ."
    )
    result, meta = _call_claude_advisory(prompt)
    _save_advisory('emergency_advisory',
                   {'user_text': text, 'alert_summary': alert_summary, 'context': context_str},
                   result, meta)
    return result


def _ai_strategy_advisory(text: str) -> str:
    """Strategy: gather indicators + news + score engine + AI scenario."""
    parts = []

    # indicator snapshot (includes BTC current price)
    ind = local_query_executor.execute("indicator_snapshot")
    parts.append(f"ì§€í‘œ:\n{ind}")

    # position info
    pos = local_query_executor.execute("position_info")
    parts.append(f"í¬ì§€ì…˜:\n{pos}")

    # score engine (includes NEWS_EVENT)
    score = local_query_executor.execute("score_summary")
    parts.append(f"ìŠ¤ì½”ì–´:\n{score}")

    # vol summary
    vol = local_query_executor.execute("volatility_summary")
    parts.append(f"ë³€ë™ì„±:\n{vol}")

    # vol profile (POC/VAH/VAL)
    vp = _fetch_vol_profile()
    if vp:
        parts.append(f"ë³¼ë¥¨ í”„ë¡œíŒŒì¼:\n{vp}")

    # news
    news = local_query_executor.execute("news_summary", "ìµœê·¼ 6ì‹œê°„ ë‰´ìŠ¤ 5ê°œ")
    parts.append(f"ë‰´ìŠ¤:\n{news[:600]}")

    prompt = (
        f"ë‹¹ì‹ ì€ ë¹„íŠ¸ì½”ì¸ ì„ ë¬¼ íŠ¸ë ˆì´ë”© ë¶„ì„ê°€ì…ë‹ˆë‹¤.\n"
        f"ì•„ë˜ ì œê³µëœ ì‹¤ì‹œê°„ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”.\n"
        f"ì§€ì§€/ì €í•­ ë ˆë²¨ì€ ë°˜ë“œì‹œ ì•„ë˜ Bollinger Band, Ichimoku, MA, Volume Profile ê°’ì—ì„œ ë„ì¶œí•˜ì„¸ìš”.\n"
        f"ì ˆëŒ€ë¡œ ì¼ë°˜ ì§€ì‹ì´ë‚˜ ê³¼ê±° í•™ìŠµ ë°ì´í„°ì˜ ê°€ê²© ë ˆë²¨ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n\n"
        f"ì‚¬ìš©ì ìš”ì²­: {text}\n\n"
        f"=== ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ===\n" + "\n\n".join(parts) + "\n\n"
        "=== ë¶„ì„ ìš”ì²­ ===\n"
        "1. í˜„ì¬ ì¶”ì„¸/êµ­ë©´ íŒë‹¨ (ìŠ¤ì½”ì–´ ì—”ì§„ 4ì¶• ì¢…í•©)\n"
        "2. ë‰´ìŠ¤ ì´ë²¤íŠ¸ ìŠ¤ì½”ì–´ê°€ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥\n"
        "3. ì „ëµ ì‹œë‚˜ë¦¬ì˜¤ 2~3ê°œ\n"
        "4. í•µì‹¬ ì§€ì§€/ì €í•­ ë ˆë²¨ (ìœ„ BB/Ichimoku/MA/POCì—ì„œ ë„ì¶œ) + ëŒ€ì‘ í¬ì¸íŠ¸\n"
        "â€» ë§¤ë§¤ ì‹¤í–‰ ê¶Œí•œ ì—†ìŒ. ë¶„ì„/ê¶Œê³ ë§Œ. 800ì ì´ë‚´."
    )
    result, meta = _call_claude_advisory(prompt)
    _save_advisory('strategy',
                   {'user_text': text, 'indicators': ind, 'position': pos,
                    'score': score, 'volatility': vol, 'vol_profile': vp,
                    'news': news[:600]},
                   result, meta)
    return result


def _fetch_vol_profile() -> str:
    """Fetch latest volume profile (POC/VAH/VAL) from DB."""
    try:
        import psycopg2
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST", "localhost"),
            port=int(os.getenv("DB_PORT", "5432")),
            dbname=os.getenv("DB_NAME", "trading"),
            user=os.getenv("DB_USER", "bot"),
            password=os.getenv("DB_PASS", "botpass"),
            connect_timeout=10,
            options="-c statement_timeout=10000",
        )
        conn.autocommit = True
        with conn.cursor() as cur:
            cur.execute("""
                SELECT poc, vah, val, ts FROM vol_profile
                WHERE symbol = 'BTC/USDT:USDT'
                ORDER BY ts DESC LIMIT 1;
            """)
            row = cur.fetchone()
        conn.close()
        if row:
            return (f"  POC(ì£¼ìš”ê°€ê²©ëŒ€): ${float(row[0]):,.1f}\n"
                    f"  VAH(ìƒë‹¨): ${float(row[1]):,.1f}\n"
                    f"  VAL(í•˜ë‹¨): ${float(row[2]):,.1f}\n"
                    f"  ê¸°ì¤€ì‹œì : {row[3]}")
        return ""
    except Exception:
        return ""


def _ai_general_advisory(text: str) -> str:
    """General AI query."""
    prompt = (
        f"ì‚¬ìš©ì ì§ˆë¬¸: {text}\n\n"
        "ë¹„íŠ¸ì½”ì¸ ì„ ë¬¼ íŠ¸ë ˆì´ë”©ë´‡ ìš´ì˜ìì—ê²Œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì¤˜.\n"
        "â€» ë§¤ë§¤ ì‹¤í–‰ ê¶Œí•œ ì—†ìŒ. ë¶„ì„/ê¶Œê³ ë§Œ. 500ì ì´ë‚´."
    )
    start_ms = int(time.time() * 1000)
    result = _call_gpt_advisory(prompt)
    elapsed = int(time.time() * 1000) - start_ms
    gpt_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    _save_advisory('general_gpt',
                   {'user_text': text},
                   result,
                   {'model': gpt_model, 'api_latency_ms': elapsed, 'fallback_used': False})
    return result


def _call_claude_advisory(prompt: str) -> tuple:
    """Claude (Anthropic) call for complex analysis. Never trades.
    Returns (text_response, metadata_dict).
    """
    start_ms = int(time.time() * 1000)
    try:
        import anthropic
        from dotenv import load_dotenv
        load_dotenv("/root/trading-bot/app/.env")
        key = os.getenv("ANTHROPIC_API_KEY", "")
        if not key:
            _log("ANTHROPIC_API_KEY missing, falling back to GPT")
            elapsed = int(time.time() * 1000) - start_ms
            gpt_text = _call_gpt_advisory(prompt, provider_override="gpt-mini(fallback)")
            return (gpt_text, {'model': 'gpt-4o-mini(fallback)',
                               'api_latency_ms': elapsed, 'fallback_used': True})
        client = anthropic.Anthropic(api_key=key)
        resp = client.messages.create(
            model="claude-sonnet-4-5-20250929",
            max_tokens=800,
            messages=[{"role": "user", "content": prompt}],
        )
        text = resp.content[0].text.strip()[:3500]
        elapsed = int(time.time() * 1000) - start_ms
        return (text, {'model': 'claude-sonnet-4-5-20250929',
                       'api_latency_ms': elapsed, 'fallback_used': False})
    except Exception as e:
        _log(f"Claude error: {e}, falling back to GPT")
        elapsed = int(time.time() * 1000) - start_ms
        gpt_text = _call_gpt_advisory(prompt, provider_override="gpt-mini(fallback)")
        return (gpt_text, {'model': 'gpt-4o-mini(fallback)',
                           'api_latency_ms': elapsed, 'fallback_used': True})

def _call_gpt_advisory(prompt: str, provider_override: str = "") -> str:
    """Single GPT call for advisory. Never trades."""
    try:
        from openai import OpenAI
        key = os.getenv("OPENAI_API_KEY", "")
        if not key:
            return "âš ï¸ OPENAI_API_KEY ë¯¸ì„¤ì •. ë¡œì»¬ ì¡°íšŒë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        client = OpenAI(api_key=key, timeout=15)
        resp = client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
            messages=[{"role": "user", "content": prompt}],
            max_tokens=600,
            temperature=0.3,
        )
        return resp.choices[0].message.content.strip()[:3500]
    except Exception as e:
        return f"âš ï¸ AI ë¶„ì„ ì‹¤íŒ¨: {e}\në¡œì»¬ ì¡°íšŒëŠ” ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤."

# â”€â”€ DB save helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _save_advisory(kind, input_packet, response_text, metadata):
    """Save Claude/GPT advisory to DB. Silent on error."""
    try:
        import psycopg2
        import save_claude_analysis
        conn = psycopg2.connect(
            host=os.getenv("DB_HOST", "localhost"),
            port=int(os.getenv("DB_PORT", "5432")),
            dbname=os.getenv("DB_NAME", "trading"),
            user=os.getenv("DB_USER", "bot"),
            password=os.getenv("DB_PASS", "botpass"),
            connect_timeout=10,
            options="-c statement_timeout=30000",
        )
        conn.autocommit = True
        output = {
            'recommended_action': 'ADVISORY',
            'risk_level': None,
            'confidence': None,
            'reason_bullets': [],
            'ttl_seconds': None,
            'api_latency_ms': metadata.get('api_latency_ms'),
            'fallback_used': metadata.get('fallback_used', False),
            'response_text': response_text,
        }
        with conn.cursor() as cur:
            ca_id = save_claude_analysis.save_analysis(
                cur, kind=kind, input_packet=input_packet, output=output,
                model_used=metadata.get('model', 'unknown'))
            if ca_id:
                save_claude_analysis.create_pending_outcome(cur, ca_id, 'ADVISORY')
        conn.close()
    except Exception as e:
        _log(f"_save_advisory silent error: {e}")

# â”€â”€ main command handler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _footer(intent_name: str, route: str, provider: str) -> str:
    return f"\nâ”€\n[{intent_name}] route={route} provider={provider}"

def handle_command(text: str) -> str:
    t = (text or "").strip()

    # 1. Direct commands â€” zero GPT cost
    if t in ("/help", "help"):
        return HELP_TEXT + _footer("help", "direct", "local")
    if t in ("/health", "health"):
        return local_query_executor.execute("health_check") + _footer("health", "local", "local")
    if t in ("/status", "status"):
        return local_query_executor.execute("status_full") + _footer("status", "local", "local")

    # 2. GPT Router â€” classify intent
    try:
        intent = gpt_router.classify_intent(t)
    except Exception:
        intent = gpt_router._keyword_fallback(t)

    route = intent.get("route", "none")
    intent_name = intent.get("intent", "other")
    _log(f"intent={intent_name} route={route} "
         f"local_qtype={intent.get('local_query_type','')} "
         f"fallback={intent.get('_fallback', False)} "
         f"budget_exceeded={intent.get('_budget_exceeded', False)}")

    # 3. Cooldown hit
    if intent.get("_cooldown_hit"):
        return "â³ ë™ì¼ ìš”ì²­ì´ ìµœê·¼ì— ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    # 4. Route: local (NO AI) â€” but news may upgrade to claude
    if route == "local":
        qtype = intent.get("local_query_type", "status_full")

        if intent.get("intent") == "news":
            high = _check_news_importance()
            if high:
                _log("news upgrade â†’ claude (high impact detected)")
                return _ai_news_advisory(t, high) + _footer(intent_name, "claude", "anthropic")

        return local_query_executor.execute(qtype, original_text=t) + _footer(intent_name, "local", "local")

    # 5. Route: claude (AI advisory)
    if route == "claude":
        provider = "anthropic"
        if intent_name == "other":
            provider = "gpt-mini"
        return _ai_advisory(intent, t) + _footer(intent_name, "claude", provider)

    # 6. Route: none / other
    return (
        "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
        "ì˜ˆì‹œ: ìƒíƒœ, ë‰´ìŠ¤, í¬ì§€ì…˜, BTC ê°€ê²©, ì „ëµ ë¶„ì„, ì—ëŸ¬ í™•ì¸\n"
        "/help ë¡œ ì „ì²´ ëª©ë¡ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    ) + _footer("none", "none", "local")

# â”€â”€ main loop (unchanged) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    env = load_env(ENV_PATH)
    token = env.get("TELEGRAM_BOT_TOKEN", "").strip()
    allowed_chat_id = int(env.get("TELEGRAM_ALLOWED_CHAT_ID", "0"))
    offset_file = env.get("TELEGRAM_OFFSET_FILE",
                          "/root/.openclaw/telegram/update-offset-default.json")

    if not token or allowed_chat_id == 0:
        raise SystemExit("ENV missing: TELEGRAM_BOT_TOKEN / TELEGRAM_ALLOWED_CHAT_ID")

    last_id = read_offset(offset_file)

    resp = tg_api_call(token, "getUpdates", {
        "offset": str(last_id + 1),
        "timeout": "0",
    })

    if not resp.get("ok"):
        raise SystemExit(f"getUpdates failed: {resp}")

    results = resp.get("result", [])
    if not results:
        return

    max_update_id = last_id
    for u in results:
        update_id = int(u.get("update_id", 0))
        max_update_id = max(max_update_id, update_id)

        msg = u.get("message") or u.get("edited_message") or {}
        chat = msg.get("chat") or {}
        chat_id = int(chat.get("id", 0))
        text = (msg.get("text") or "").strip()

        if chat_id != allowed_chat_id:
            continue
        if not text:
            continue

        try:
            reply = handle_command(text)
        except Exception as e:
            _log(f"handle_command error: {e}")
            _log_err(f"handle_command error: {e}")
            reply = f"âš ï¸ ëª…ë ¹ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"
        try:
            send_message(token, chat_id, reply)
        except Exception as e:
            _log(f"send_message error: {e}")
            _log_err(f"send_message error: {e}")

    write_offset(offset_file, max_update_id)

if __name__ == "__main__":
    try:
        main()
    except FileNotFoundError as e:
        print(f"{LOG_PREFIX} FATAL: {e}", flush=True)
        _log_err(f"FATAL: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"{LOG_PREFIX} ERROR: {e}", flush=True)
        _log_err(f"ERROR: {e}")
        sys.exit(1)
